{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "siamese_network.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "E1z6dIBdPLLP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Siamese Network\n",
        "\n",
        "This notebook shows how to implement siamese network architecture to train a new embedding space.\n",
        "We will be using Cifar10 dataset, that contains ten differents classes."
      ]
    },
    {
      "metadata": {
        "id": "xjSqG8aSPLLQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Dependecies"
      ]
    },
    {
      "metadata": {
        "id": "-_OcxABAPRAG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "b02d6190-adfd-439c-d1c0-f0ae84748116"
      },
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 591.8MB 28kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x62702000 @  0x7f20e5e942a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hCollecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 22.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 3.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Installing collected packages: torch, pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.3.0 torch-1.0.0 torchvision-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "esQrLY2oPLLR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch import optim\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sa7KU8ynPLLU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Hyperparmeters"
      ]
    },
    {
      "metadata": {
        "id": "Ktx4ubO8PLLV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Setting data loaders batch size\n",
        "batch_size = 64\n",
        "\n",
        "# percentage of the training data for validation data\n",
        "valid_size = 0.2\n",
        "\n",
        "# Specify the image classes\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dv8vOfYxPLLY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Data Augmentation Pipeline"
      ]
    },
    {
      "metadata": {
        "id": "2jQgVszwPLLZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Desing a Data Augmentation pipeline\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PaOTPNDgPLLc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Load Dataset"
      ]
    },
    {
      "metadata": {
        "id": "a5y3NuvfPLLe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "589899de-d930-4f11-bc98-e6c1d2ed7285"
      },
      "cell_type": "code",
      "source": [
        "# Load training data\n",
        "train_data = datasets.CIFAR10('data', train=True, download=True, transform=transform)\n",
        "# Load testing data\n",
        "test_data = datasets.CIFAR10('data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E6gT27g8PLLl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Split Validation data"
      ]
    },
    {
      "metadata": {
        "id": "5V86obV4PLLm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Shuffling and calculating the split indexes\n",
        "train_size = len(train_data)\n",
        "split = int(train_size * (1.0 - valid_size))\n",
        "shuffle_idx = np.random.permutation(train_size)\n",
        "train_idx, valid_idx = shuffle_idx[:split], shuffle_idx[split:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Mb6Vx5-PLLs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Defining train and valid samplers\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "np.random.shuffle(train_idx)\n",
        "train_sampler2 = SubsetRandomSampler(train_idx)\n",
        "\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "np.random.shuffle(valid_idx)\n",
        "valid_sampler2 = SubsetRandomSampler(valid_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Y8wkkeWPLL0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Data loaders"
      ]
    },
    {
      "metadata": {
        "id": "nv5ersVFPLL1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
        "train_loader2 = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler2)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler)\n",
        "valid_loader2 = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler2)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U-smKxCTPLL9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Convolutional Network Architecture"
      ]
    },
    {
      "metadata": {
        "id": "X0qIlVRVPLL-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        # input: 32x32x3 --- output: 32x32x32\n",
        "        self.conv1_1 = nn.Conv2d(3, 32, 5, padding=2)\n",
        "        # input: 32x32x32 --- output: 32x32x64\n",
        "        self.conv1_2 = nn.Conv2d(32, 64, 5, padding=2)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        # MaxPooling Here then...\n",
        "        \n",
        "        # input: 16x16x32 --- output: 16x16x128\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        # input: 16x16x128 --- output: 16x16x256\n",
        "        self.conv2_2 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(256)\n",
        "        \n",
        "        # MaxPooling Here then...\n",
        "        \n",
        "        # input: 8x8x256 --- output: 8x8x512\n",
        "        self.conv3_1 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(512)\n",
        "        # MaxPooling Here then...\n",
        "        \n",
        "        # input: 4x4x512 --- output: 4x4x1024\n",
        "        self.conv4_1 = nn.Conv2d(512, 1024, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(1024)\n",
        "        # MaxPooling Here then...\n",
        "        \n",
        "        # input: 2x2x1024      \n",
        "        self.fc1 = nn.Linear(2 * 2 * 1024, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 256)\n",
        "        self.fc3 = nn.Linear(256, 64)      \n",
        "        self.fc4 = nn.Linear(64, 64)        \n",
        "        \n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        # Conv Block 1\n",
        "        x = F.relu(self.conv1_1(x))\n",
        "        x = F.relu(self.conv1_2(x))\n",
        "        x = self.pool(self.bn1(x))\n",
        "        \n",
        "        # Conv Block 2\n",
        "        x = F.relu(self.conv2_1(x))\n",
        "        x = F.relu(self.conv2_2(x))\n",
        "        x = self.pool(self.bn2(x))\n",
        "        \n",
        "        # Conv Block 3\n",
        "        x = F.relu(self.conv3_1(x))\n",
        "        x = self.pool(self.bn3(x))\n",
        "        \n",
        "        # Conv Block 4\n",
        "        x = F.relu(self.conv4_1(x))\n",
        "        x = self.pool(self.bn4(x))\n",
        "        \n",
        "        # Flatten\n",
        "        x = x.view(-1, 2 * 2 * 1024)\n",
        "        \n",
        "        # Fully Connected Layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "        \n",
        "        #print(x)\n",
        "        \n",
        "        # L2-Normalization\n",
        "        x_norm2 = torch.sqrt(torch.sum(x**2)) + 0.0001\n",
        "        x = x / x_norm2\n",
        "        #print(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r5Vkho4FPLMB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "#print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ppESIg1VPLMF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Siamese Network"
      ]
    },
    {
      "metadata": {
        "id": "9Uyc6K1RPLMI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SiameseNetwork(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.cnn = CNN()\n",
        "        \n",
        "    \n",
        "    def forward(self, x1, x2):\n",
        "        \n",
        "        x1 = self.cnn.forward(x1)\n",
        "        x2 = self.cnn.forward(x2)\n",
        "        #print(x1)\n",
        "        # Calculate Euclidean distance \n",
        "        distance = torch.sqrt(torch.sum((x1 - x2)**2))\n",
        "        #print(distance)\n",
        "        return distance\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "05ZpvGwaPLML",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = SiameseNetwork()\n",
        "\n",
        "if train_on_gpu:\n",
        "    model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7MpbptGdPLMQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Training parameters"
      ]
    },
    {
      "metadata": {
        "id": "VjrA3teSPLMR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Define Contrastive loss"
      ]
    },
    {
      "metadata": {
        "id": "mzB15sBgPLMT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def contrastive_loss(dist, y):\n",
        "    margin = 0.5\n",
        "    y = y.type(torch.cuda.FloatTensor)\n",
        "    dist = dist.view(-1, 1)\n",
        "    zeros = torch.zeros_like(dist)\n",
        "    margin_dist = torch.cat((margin - dist, zeros), dim=1)\n",
        "    \n",
        "    #print(margin_dist, torch.max(margin_dist, 1)[0])\n",
        "    not_same_loss = y * torch.max(margin_dist, 1)[0]\n",
        "    #print(\"not_same\", not_same_loss)\n",
        "    same_loss = -(y - 1) * dist\n",
        "    #print(\"same\" , same_loss)\n",
        "    #print(-torch.sum(same_loss + not_same_loss)/64.0)\n",
        "    return torch.sum(same_loss + not_same_loss)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pCVXPqVTPLMY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Optimizer"
      ]
    },
    {
      "metadata": {
        "id": "m_t-Ne3ZPLMZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IY3uBPY2PLMh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Training"
      ]
    },
    {
      "metadata": {
        "id": "fPCDBQsNPLMj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "c2cb1c4b-0286-4416-8498-fbe15647a09c"
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    for (x1, y1), (x2, y2) in zip(train_loader, train_loader2):\n",
        "        y = (y1 != y2)\n",
        "        \n",
        "        if train_on_gpu:\n",
        "            x1, x2, y = x1.cuda(), x2.cuda(), y.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model.forward(x1, x2)\n",
        "        #print(output)\n",
        "        loss = contrastive_loss(output, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for (x1, y1), (x2, y2) in zip(valid_loader, valid_loader2):\n",
        "        y = (y1 != y2)\n",
        "        if train_on_gpu:\n",
        "            x1, x2, y = x1.cuda(), x2.cuda(), y.cuda()\n",
        "            \n",
        "        output = model.forward(x1, x2)\n",
        "        \n",
        "        loss = contrastive_loss(output, y)\n",
        "        \n",
        "        valid_loss += loss.item()\n",
        "        \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch, train_loss/len(train_loader), valid_loss/len(valid_loader)))"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 \tTraining Loss: 3.973100 \tValidation Loss: 4.386705\n",
            "Epoch: 1 \tTraining Loss: 3.764825 \tValidation Loss: 4.013046\n",
            "Epoch: 2 \tTraining Loss: 3.759655 \tValidation Loss: 4.634603\n",
            "Epoch: 3 \tTraining Loss: 3.798429 \tValidation Loss: 6.310864\n",
            "Epoch: 4 \tTraining Loss: 3.607473 \tValidation Loss: 7.686930\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "08EbDVqBPLM1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Show results"
      ]
    },
    {
      "metadata": {
        "id": "DSWhyV_UPLM2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61d2e37e-fabf-4952-a2a5-be3eb2b7c51f"
      },
      "cell_type": "code",
      "source": [
        "split"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "metadata": {
        "id": "sxA4vxwnyzaX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}